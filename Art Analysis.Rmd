---
title: "Bachelor Thesis Analysis"
author: "Pernille Berg Lassen"
date: "25 sep 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---
Steps:

1) Qualitity checks of the eye-tracking data
1.a) Looking at my population (behavioral data)
  Mean age
  The art-interest scores (q8+q9+q10+q11)
  Familiarity (q7) - how familiar were the artworks to the population?
2) Vizualitions (Both behavioral and eye-tracking data)
  Behavioral: Bar plots
  ET: Heat maps and scan paths (see port 1 4th sem)
3) Models
  Behavioral: (g)lmer
    a. calculating mean score of rating (q1+q2+q3/3) and understanding (q4+q5+q6/3) for each image
  ET: glmer
4) Saliency algoritm
  ET: looking at the effect of saliency 
  ROC and AUC
6) CV of models


Loading packages 
```{r}
library(devtools)
library(tidyverse)
library(data.table)
library(ggpubr)
library(caret)
library(lmerTest)
library(lme4)

```

Are the groups well-balanced? Preliminary Data exploration

```{r}
#Loading data
BehaveDat = read.csv("BehavioralData_New.csv", header = T) #Behavioural Data only
BehaveDat = subset(BehaveDat, select = -c(X))

SacDat = read.csv("SaccadesData_New.csv",header = T) #ET data for saccades + Behavioural Data
SacDat = subset(SacDat, select = -c(X))
SacDat = subset(SacDat, select = -c(Number_sac))

#Removing saccades with a duration over 80 
SacDat = subset(SacDat,SacDat$Duration < 80)

FixDat = read.csv("FixationsData_New.csv", header = T) #ET data for fixations + Behavioural Data
FixDat = subset(FixDat, select = -c(X))
FixDat = subset(FixDat, select = -c(Number_fix))

FixDat2 = read.csv("FixationsData_New.csv", header = T)
#Removing fixations below 200 ms
FixDat2 = subset(FixDat2,FixDat2$Duration > 200)

#Recalculate num_fix and num_sac
count = group_by(FixDat,image,ID) %>% summarize(Number_fix=n())
countSac = group_by(SacDat,image,ID) %>% summarize(Number_sac=n())
Fix_df = plyr::join(FixDat,count)
Sac_df = plyr::join(SacDat,countSac)
Fix_df$PositionY = 901-PositionY

#Looking at the population:
Experts = subset(BehaveDat, condition == 1)
NonExperts = subset(BehaveDat, condition == 0)
summary(Experts$gender)/40 #The reason female is not a whole number - ID 1 saw only 39 images
summary(NonExperts$gender)/40
mean(Experts$age)
mean(NonExperts$age)
summary(BehaveDat$q7)/27
summary(BehaveDat$q7[BehaveDat$condition == 1])/13
summary(BehaveDat$q7[BehaveDat$condition == 0])/14
summary(BehaveDat$image[BehaveDat$q7 == "yes"]) #Most familiar images - so far it's schiele
length(BehaveDat$ID[BehaveDat$q11 == "yes"])/40 #How many people have taken art-classes? - again, not a whole number because of ID 1
summary(BehaveDat$image[BehaveDat$q7 == "yes"])

BehaveDat2 <- BehaveDat %>% #summarizing mean of ratings for each participants 
  group_by(ID) %>%
  summarize(
    q1 = q1[1],
    q2 = q2[1],
    q3 = q3[1],
    q4 = q4[1],
    q5 = q5[1],
    q6 = q6[1],
    q7 = q7[1],
    q8 = q8[1],
    q9 = q9[1],
    q10 = q10[1],
    q11 = q11[1],
    condition = condition[1]
  )

plot1 <- ggplot(BehaveDat2,aes(y=q1,x=condition))+geom_boxplot()+ggtitle("Go to a museum to see this picture?")+
  xlab("Condition") + ylab("Rating")+ coord_cartesian(ylim = c(1, 7))
plot2 <- ggplot(BehaveDat2,aes(y=q2,x=condition))+geom_boxplot()+ggtitle("Recommend others to do the same?")+
  xlab("Condition") + ylab("Rating")+ coord_cartesian(ylim = c(1, 7))
plot3 <- ggplot(BehaveDat2,aes(y=q3,x=condition))+geom_boxplot()+ggtitle("Buy this picture?")+
  xlab("Condition") + ylab("Rating")+ coord_cartesian(ylim = c(1, 7))
plot4 <- ggplot(BehaveDat2,aes(y=q4,x=condition))+geom_boxplot()+ggtitle("Explain the main idea?")+
  xlab("Condition") + ylab("Rating")+ coord_cartesian(ylim = c(1, 7))
plot5 <- ggplot(BehaveDat2,aes(y=q5,x=condition))+geom_boxplot()+ggtitle("Identify other artworks by same artist? ")+ coord_cartesian(ylim = c(1, 7))+
  xlab("Condition") + ylab("Rating")
plot6 <- ggplot(BehaveDat2,aes(y=q6,x=condition))+geom_boxplot()+ggtitle("Explain the main idea behind similar artworks?")+ coord_cartesian(ylim = c(1, 7))+
  xlab("Condition") + ylab("Rating")

ggarrange(
  plot1,
  plot2,
  plot3
)



#plot7 <- ggplot(BehaveDat2,aes(x=q7))+geom_bar(fill = "#999999")+facet_wrap(~condition)+
 # xlab("Question 7") + ylab("Number of Participants")
plot8 <- ggplot(BehaveDat2,aes(y=q8,x=condition))+geom_boxplot()+xlab("Condition")+ylab("Rating")+ggtitle("Question 8")+coord_cartesian(ylim = c(1, 7))
plot9 <- ggplot(BehaveDat2,aes(y=q9,x=condition))+geom_boxplot()+xlab("Condition")+ylab("Rating")+ggtitle("Question 9")+ coord_cartesian(ylim = c(1, 7))
plot10 <- ggplot(BehaveDat2,aes(y=q10,x=condition))+geom_boxplot()+xlab("Condition")+ylab("Rating") + ggtitle("Question 10") + coord_cartesian(ylim = c(1,7))
plot11 <- ggplot(BehaveDat2,aes(x = q11))+geom_bar(fill = "#999999")+facet_wrap(~condition)+ xlab("Question 11") + ylab("Number of Participants")+ggtitle("Question 11")

BehaveDat2$q11 = plyr::revalue(BehaveDat2$q11,c("yes"="1","no"="0"))

ggarrange(
  plot8,
  plot9,
  plot10,
  plot11
)

ggarrange(
  plot7,
  plot11

)

#Group 1 appears to be more intersted in art - could be influenced by the briefing 
#Let's test if the difference is signifcant
#$q8 = as.factor(BehaveDat2$q8)
#BehaveDat2$q9 = as.factor(BehaveDat2$q9)
#BehaveDat2$q10 = as.factor(BehaveDat2$q10)

mean(BehaveDat2$q8[BehaveDat2$condition == 1])
sd(BehaveDat$q8[BehaveDat2$condition == 1])
mean(BehaveDat2$q8[BehaveDat2$condition == 0])
sd(BehaveDat$q8[BehaveDat2$condition == 0])

mean(BehaveDat2$q9[BehaveDat2$condition == 1])
sd(BehaveDat$q9[BehaveDat2$condition == 1])
mean(BehaveDat2$q9[BehaveDat2$condition == 0])
sd(BehaveDat$q9[BehaveDat2$condition == 0])

mean(BehaveDat2$q10[BehaveDat2$condition == 1])
sd(BehaveDat$q10[BehaveDat2$condition == 1])
mean(BehaveDat2$q10[BehaveDat2$condition == 0])
sd(BehaveDat$q10[BehaveDat2$condition == 0])


mq7 = glm(q7 ~ condition, family = "binomial", BehaveDat2)
mq8 = glm(condition ~ 1 + q8, family = "binomial", BehaveDat2)
mq9 = glm(condition ~ 1 + q9, family = "binomial", BehaveDat2)
mq10 = glm(condition ~ q10, family = "binomial",BehaveDat2)
mq11 = glm(q11 ~ condition, family = "binomial", BehaveDat2)

BehaveDat2$q11 = plyr::revalue(BehaveDat2$q11,c("1"="yes","0"="no"))
```

Assessing quality of ET-data
```{r}
#Heatmaps and scanpaths
#Subsetting dataframe to make heatmaps for 4 chosen images - all participants included
#Average across all participants?

averaged_heatmaps <- Fix_df %>%
  group_by(image) %>%
  mutate(Counter = sequence(rle(ID)$lengths)) %>%
  ungroup() %>%
  group_by(image, Counter) %>%
  summarize(
    PositionX = median(PositionX),
    PositionY = median(PositionY)
  )


averaged_heatmapsC0 <- subset(Fix_df, condition == 0) %>%
  group_by(image) %>%
  mutate(Counter = sequence(rle(ID)$lengths)) %>%
  ungroup() %>%
  group_by(image, Counter) %>%
  summarize(
    PositionX = median(PositionX),
    PositionY = median(PositionY)
  )

averaged_heatmapsC1 <- subset(Fix_df, condition == 1) %>%
  group_by(image) %>%
  mutate(Counter = sequence(rle(ID)$lengths)) %>%
  ungroup() %>%
  group_by(image, Counter) %>%
  summarize(
    PositionX = median(PositionX),
    PositionY = median(PositionY),
    Condition = condition[1]
  )


jet.colors = colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))

img <- png::readPNG("images for heatmaps and scanpaths/screenshot_fig11.png")
g <- grid::rasterGrob(img, interpolate = T)

aveHM = ggplot(subset(averaged_heatmaps, image == "images_schiele\\fig_11.png"),aes(x = PositionX, y = PositionY)) +
  xlim(0,1600) +
  ylim(0,900) +
  annotation_custom(g,xmin=-Inf, xmax=Inf, ymin=-0, ymax=900) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) + scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans='sqrt') + ggtitle("All Participants")

aveHMC1 = ggplot(subset(averaged_heatmapsC1, image == "images_pollock\\abstract_17.png"),aes(x = PositionX, y = 901-PositionY)) +
  xlim(0,1600) +
  ylim(0,900) +
  annotation_custom(g,xmin=-Inf, xmax=Inf, ymin=-0, ymax=900) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) + scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans='sqrt') + ggtitle("Condition 1")

aveHMC0 = ggplot(subset(averaged_heatmapsC0, image == "images_pollock\\abstract_17.png"),aes(x = PositionX, y = 901-PositionY)) +
  xlim(0,1600) +
  ylim(0,900) +
  annotation_custom(g,xmin=-Inf, xmax=Inf, ymin=-0, ymax=900) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) + scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans='sqrt') + ggtitle("Condition 0")

ggarrange(
  aveHM,
  aveHM2
)


#Scanpath 
img <- png::readPNG("images for heatmaps and scanpaths/screenshot_fig11.png")
g <- grid::rasterGrob(img,interpolate = T)

aveSP = ggplot(subset(averaged_heatmaps, image == "images_schiele\\fig_11.png"), aes(x = PositionX, y = 901-PositionY)) +
  xlim(0, 1600) +
  ylim(0, 900) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=900) +
  geom_point(size = 8, alpha = 0.5, color = "white") + 
  geom_path(size = 1, alpha = 0.3) + 
  geom_text(aes(label = Counter, size = 5)) +
  ggtitle("All Participants")

aveSPC1 = ggplot(subset(averaged_heatmapsC1, image == "images_schiele\\fig_11.png"), aes(x = PositionX, y = 901-PositionY)) +
  xlim(0, 1600) +
  ylim(0, 900) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=900) +
  geom_point(size = 8, alpha = 0.5, color = "white") + 
  geom_path(size = 1, alpha = 0.3) + 
  geom_text(aes(label = Counter, size = 5)) + 
  ggtitle("Condition 1")

aveSPC0 = ggplot(subset(averaged_heatmapsC0, image == "images_schiele\\fig_11.png"), aes(x = PositionX, y = 901-PositionY)) +
  xlim(0, 1600) +
  ylim(0, 900) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=900) +
  geom_point(size = 8, alpha = 0.5, color = "white") + 
  geom_path(size = 1, alpha = 0.3) + 
  geom_text(aes(label = Counter, size = 5))+ 
  ggtitle("Condition 0")



FixDat$Duration = as.numeric(FixDat$Duration)

#Density plot for saccades and fixation duration - Poisson
ggplot(SacDat, aes(Duration, na.rm = T)) + geom_density()

ggplot(FixDat, aes(Duration,na.rm = T)) + geom_density() 

#Density for number of fix and sac
SacDat2  <- SacDat %>% 
  group_by(ID) %>%
  summarize(Number_sac = Number_sac[1])

FixDat2  <- FixDat %>% 
  group_by(ID) %>%
  summarize(Number_fix = Number_fix[1])

ggplot(FixDat2, aes(Number_fix,na.rm = T)) + geom_density()
ggplot(SacDat2, aes(Number_sac,na.rm = T)) + geom_density()

```

#Behavioral models - can difference in ratings be explained by condition?

```{r}
BehaveDat3 <- BehaveDat %>% #summarizing mean of ratings for each participants 
  group_by(ID) %>%
  summarize(
    condition = condition[1],
    q1 = q1[1],
    q2 = q2[1],
    q3 = q3[1],
    q4 = q4[1],
    q5 = q5[1],
    q6 = q6[1],
    LikingMean = LikingMean[1],
    UnderstandingMean = UnderstandingMean[1]
  )

#Does it make sense to make means??? Check distributions - huge spread?  Does it matter?
ggplot(BehaveDat2, aes(q8, na.rm = T)) + geom_density()

#Cakculate mean
BehaveDat$LikingMean = (BehaveDat$q1 + BehaveDat$q2 + BehaveDat$q3)/3
BehaveDat$UnderstandingMean = (BehaveDat$q4 + BehaveDat$q5 + BehaveDat$q6)/3

#rescalelist = c("LikingMean","UnderstandingMean") #making a list with variales we want to scale
m1.1Data.s = BehaveDat[, colnames(BehaveDat) %in% rescalelist] %>% 
  apply(.,function(x) scale(x,center= mean(x,na.rm = T), scale = sd(x, na.rm = T)))%>% 
  cbind(.,BehaveDat[,! colnames(BehaveDat) %in% rescalelist]) 

##Models will be run first with the mean, then if time with the median
#Median is more meaningful
m1.1 = lmerTest::lmer(LikingMean ~ 1 +condition + (1|ID)
                      + (1+condition|image),BehaveDat)

m1.2 = lmerTest::lmer(UnderstandingMean ~ 1 + condition +
                        (1|ID) + (1+condition|image),BehaveDat)

m1.3 = lmerTest::lmer(LikingMean ~ 1 + condition*artist 
                      + (1+artist|ID)+(1+condition|image),BehaveDat)

m1.4 = lmerTest::lmer(UnderstandingMean ~ 1 + condition*artist 
                    +(1+artist|ID)+(1+condition|image), BehaveDat)
#m1.5 = lmerTest::lmer(LikingMean ~ 1 + condition*genre 
                      #+ (1|ID)+(1|image),BehaveDat) #these two models are not surprisng given the results of the artist ones. 

#m1.6 = lmerTest::lmer(UnderstandingMean ~ 1 + condition*genre 
                      #+ (1|ID)+(1|image),BehaveDat)

```

### Eyetracking models

```{r}
#Remember! ET data is NOT normally distributed! Family = possion OR family = gaussian(log = "link")

#Making 1) df with the Number of Fix + Number og Sacs and 2) a df with the Duration of Fix and Duration of Sacs

test1 <- Fix_df %>% 
  group_by(ID, image) %>%
  summarize(
    condition = condition[1],
    Trial = Trial[1],
    Number_fix = Number_fix[1],
    artist = artist[1],
    genre = genre[1]
  )

test2 <- Sac_df %>% 
  group_by(ID, image) %>%
  summarize(
    condition = condition[1],
    Trial = Trial[1],
    Number_sac = Number_sac[1],
    artist = artist[1],
    genre = genre[1]
  )

test3 <- Fix_df %>%
  group_by(ID, image) %>%
  summarize(
    condition = condition[1],
    Trial = Trial[1],
    Duration_fix = mean(Duration),
    artist = artist[1],
    genre = genre[1]
  )

test4 <- Sac_df %>%
  group_by(ID, image) %>%
  summarize(
    condition = condition[1],
    Trial = Trial[1],
    Duration_Sac = mean(Duration),
    artist = artist[1],
    genre = genre[1]
  )


m1Data <- merge(test1,test2, by = c("ID","image"))
m1Data <- subset(m1Data, select = -c(Trial.y,condition.y,artist.y,genre.y))
m1Data <- plyr::rename(m1Data,c("condition.x"="condition","Trial.x"="Trial","artist.x"="artist","genre.x"="genre"))

m2Data <- merge(test3,test4, by = c("ID","image"))
m2Data <- subset(m2Data, select = -c(Trial.y,condition.y,artist.y,genre.y))
m2Data <- plyr::rename(m2Data,c("condition.x"="condition","Trial.x"="Trial","artist.x"="artist","genre.x"="genre"))

#Let's scale some variables (centering around the mean)
rescalelist = c("Number_fix","Number_sac") #making a list with variales we want to scale
m1Data.s = m1Data[, colnames(m1Data) %in% rescalelist] %>% 
  lapply(.,function(x) scale(x,center= mean(x,na.rm = T), scale = sd(x, na.rm = T)))%>% 
  cbind(.,m1Data[,! colnames(m1Data) %in% rescalelist]) 

rescalelist = c("Duration_fix","Duration_Sac") #making a list with variales we want to scale
m2Data.s = m2Data[, colnames(m2Data) %in% rescalelist] %>% 
  lapply(.,function(x) scale(x,center= mean(x,na.rm = T), scale = sd(x, na.rm = T)))%>% 
  cbind(.,m2Data[,! colnames(m2Data) %in% rescalelist]) 

rescalelist = c("Time_1stFix") #making a list with variales we want to scale
m3Data.s = testAOI[, colnames(testAOI) %in% rescalelist] %>% 
  lapply(.,function(x) scale(x,center= mean(x,na.rm = T), scale = sd(x, na.rm = T)))%>% 
  cbind(.,testAOI[,! colnames(testAOI) %in% rescalelist]) 

#Can condition be predicted based on fix and sac?
m2.1 <- glmer(condition ~ 1 + Number_fix*Number_sac + (1 + Number_fix*Number_sac|ID) + (1 + Number_fix*Number_sac|image), family = "binomial", data = m1Data.s, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))

m2.2 <- glmer(condition ~ 1 + Duration_fix*Duration_Sac + (1 + Duration_fix*Duration_Sac|ID) + (1 + Duration_fix*Duration_Sac|image), family = "binomial", data = m2Data.s, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))

#m2.3 <- glmer(condition ~ 1 + Time_1stFix + (1+Time_1stFix|ID) + (1+Time_1stFix|image), data = testAOI, family = "binomial", control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))

##An effect of artist and genre on ET data? 
ggplot(m1Data.s, aes(Number_fix,na.rm = T)) + geom_density()

m2.4 <- glmer(Number_fix ~ 1 + artist + (1 + artist|ID) + (1|image), family = "poisson", data = m1Data, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))

ggplot(Fix_df, aes(Duration,na.rm = T)) + geom_density()

m2.5 <- glmer(Duration_fix ~ 1 + artist + (1 + artist|ID) + (1|image), family =gaussian(link = "log"), data = m2Data, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))

ggplot(m1Data, aes(Number_sac,na.rm = T)) + geom_density()

m2.6 <- glmer(Number_sac ~ 1 + artist + (1 + artist|ID) + (1|image), family = "poisson", data = m1Data, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))

ggplot(m2Data, aes(Duration_Sac, na.rm = T)) + geom_density()

m2.7 <- glmer(Duration_Sac ~ 1 + artist + (1+artist|ID) + (1|image), family = gaussian(link = "log"), data = m2Data, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))

ggplot(testAOI, aes(Time_1stFix, na.rm = T)) + geom_density()

m2.8 <- glmer(Time_1stFix ~ 1 + artist + (1+artist|ID) + (1|image), family = "poisson", data = testAOI,control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))

```

Visualization of AUC scores from Saliency maps

```{r}
                 
#write.csv(AUC_data, "AUC_data.csv")          
AUC_data = read.csv("AUC_data.csv", header = T)

AUC_df = data.frame(Genre = c(rep("abs",20),rep("fig",20)), Condition = rep(0, 40), AUC = c(0.1884, 0.1630, 0.1513, 0.2322, 0.1226, 0.1707, 0.1640, 0.1803,
0.1838, 0.2068, 0.0628, 0.0712, 0.0738, 0.0636, 0.1939, 0.2038,
0.0790, 0.1467, 0.1565, 0.1440, 0.1438, 0.1984, 0.0659, 0.1972, 0.1690, 0.1687, 0.1955, 0.1948, 0.1746, 0.0222, 0.1922, 0.1159, 0.0404, 0.2406, 0.1887, 0.2091, 0.2046, 0.1883, 0.1791, 0.0223))

tempAUC = data.frame(Genre = c(rep("abs",20),rep("fig",20)), Condition = rep(1,40), AUC = c(0.1884, 0.1630, 0.1513, 0.2322, 0.1226, 0.1707, 0.1640, 0.1803,
0.1838, 0.2068, 0.0628, 0.0712, 0.0738, 0.0636, 0.1939, 0.2038,
0.0790, 0.1467, 0.1565, 0.1440, 0.1438, 0.1984, 0.0659, 0.1972,
0.1690, 0.1687, 0.1955, 0.1948, 0.1746, 0.0222, 0.1922, 0.1159,
0.0404, 0.2406, 0.1887, 0.2091, 0.2046, 0.1883, 0.1791, 0.0223))


AUC_df = rbind(AUC_df,tempAUC)

write.csv(AUC_df, "AUC_dataNew.csv")
AUC_df = read.csv("AUC_dataNew.csv",header = T)
AUC_df = subset(AUC_df, select = -c(X))

AUC_df$Image = str_extract(AUC_df$Genre, "\\w+")
AUC_df$Image = append(AUC_df$Image, 1:20)

AUC2 <- AUC_df %>% 
  group_by(Genre) %>%
  summarize(
  AUC = mean(AUC)
  )

ggplot(AUC_df, aes(x = Genre, y = AUC)) + geom_boxplot()+coord_cartesian(ylim = c(0, 1))

```
  
  
```{r}
  #Defing a function to get performance
getPerformance = function(test_df, train_df, mdl, mdl_string, n = NA){
  #asses performance and returns a result df
  
    #save perf to list
      #Test performance
  
  #extract predicted value from the mdl string to use in the rmse
  temp_string = gsub("(\\~).+", mdl_string, replacement = "")
  actual_col = gsub(" ", x = temp_string, replacement = "")
  actual =pull(dplyr::select(test_df, actual_col))
  #calculating rmse
  rmse = hydroGOF::rmse(predict(mdl, test_df, allow.new.levels = T), actual , na.rm = T)
  mdlPerf = summary(mdl)
    #saving performance metrix to a df
  result_df =  data.frame(rmse = rmse,
                          AIC = mdlPerf$AICtab[1],
                          BIC = mdlPerf$AICtab[2],
                          LogLik = mdlPerf$AICtab[3],
                          n = n) 
  return(result_df)
} #Getting performance
  #defining a cross validate function
CrossVal = function(num_folds, dataset, mdl_string, ID_col = NULL, CAT_col = NULL, glmer = T, link = "log") {
  
  #folding the dataset
  dataset = fold(dataset, num_folds, cat_col = CAT_col, id_col = ID_col, method = 'n_dist')
  
  #looping through the folds
  for (fold in seq(num_folds)) {
    train_df = subset(dataset, .folds != fold)
    test_df = subset(dataset, .folds == fold)
    
    if (glmer == T){
      if (link == "log"){
        #train data on all except the fold
        mdl = try(glmer(mdl_string, train_df, family = gaussian(link = "log"), 
                        control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE)))
      } else {
        #train data on all except the fold
        mdl = try(glmer(mdl_string, train_df, family = "poisson", 
                        control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE)))
      }
    } else {
      mdl = try(glmer(mdl_string, train_df, family = "binomial", 
                        control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE)))
    }
    temp_sum = try(summary(mdl))
    if (length(temp_sum) > 3){ #if you could make a model
      #asses performance and append it to a df
      temp = getPerformance(test_df, train_df, mdl, mdl_string, n = fold)
    } else {#if you couldn't make a model
      temp = data.frame(rmse = NA,
                        AIC = NA,
                        BIC = NA,
                        LogLik = NA,
                        n = n)
    }
    temp$mdl = mdl_string
    temp$numfolds = num_folds
    if (fold == 1){ #if first part - make a df
      perf_df = temp
    } else { #else append to df
      perf_df = rbind(perf_df, temp)  
    }
    
  }
  return(perf_df)
}

CV_m1 =  CrossVal(num_folds = 3, dataset = m1Data.s, mdl_string = "condition ~ 1 + Number_fix*Number_sac + (1 + Number_fix*Number_sac|ID) + (1 + Number_fix*Number_sac|image)", ID_col = "ID", CAT_col = "condition", glmer = F)

CV_m2 =  CrossVal(num_folds = 3, dataset = m2Data.s, mdl_string = "condition ~ 1 + Duration_fix*Duration_Sac + (1 + Duration_fix*Duration_Sac|ID) + (1 + Duration_fix*Duration_Sac|image)", ID_col = "ID", CAT_col = "condition", glmer = F)


perf_df1 = rbind(CV_m1,CV_m2)

perf_df1_sum = group_by(perf_df1, mdl) %>%
  summarise_all(funs(mean(., na.rm = TRUE)))


CV_m4 = CrossVal(num_folds = 3, dataset = m1Data, mdl_string = "Number_fix ~ 1 + artist + (1 + artist|ID) + (1|image)", ID_col = "ID", CAT_col = "condition", glmer = T)

CV_m5 = CrossVal(num_folds = 3, dataset = m2Data, mdl_string = "Duration_fix ~ 1 + artist + (1 + artist|ID) + (1|image)", ID_col = "ID", CAT_col = "condition", glmer = T, link = "log")

CV_m6 = CrossVal(num_folds = 3, dataset = m1Data, mdl_string = "Number_sac ~ 1 + artist + (1 + artist|ID) + (1|image)", ID_col = "ID", CAT_col = "condition", glmer = T)

CV_m7 = CrossVal(num_folds = 3, dataset = m2Data, mdl_string = "Duration_Sac ~ 1 + artist + (1 + artist|ID) + (1|image)", ID_col = "ID", CAT_col = "condition", glmer = T, link = "log")

CV_m8 = CrossVal(num_folds = 3, dataset = testAOI, mdl_string = "Time_1stFix ~ 1 + artist + (1 + artist|ID) + (1|image)", ID_col = "ID", CAT_col = "condition", glmer = T)

perf_df2 = rbind(CV_m4,CV_m5, CV_m6, CV_m7,CV_m8)

perf_df2_sum = group_by(perf_df2, mdl) %>%
  summarise_all(funs(mean(., na.rm = TRUE)))



```
