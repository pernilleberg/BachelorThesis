---
title: "Bachelor Thesis Analysis"
author: "Pernille Berg Lassen"
date: "25 sep 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---
Steps:
1) Data cleaning
2) Qualitity checks of the eye-tracking data
2.a) Looking at my population (behavioral data)
  Mean age
  The art-interest scores (q8+q9+q10+q11)
  Familiarity (q7) - how familiar were the artworks to the population?
3) Vizualitions (Both behavioral and eye-tracking data)
  Behavioral: Bar plots
  ET: Heat maps and scan paths (see port 1 4th sem)
4) Models
  Behavioral: (g)lmer
    a. calculating mean score of rating (q1+q2+q3/3) and understanding (q4+q5+q6/3) for each image
  ET: glmer
5) Saliency algoritm
  ET: looking at the effect of saliency 
  ROC and AUC
6) CV of models


Loading packages, loading data and cleaning datasets
```{r}

#Sal_abs14 = read.csv("abs14.csv", header = T)

library(devtools)
library(tidyverse)
library(data.table)
#library(knitr)
library(ggpubr)
#library(stringr)
#library(caret)
library(lmerTest)
#library(matlabr)
```

Are the groups well-balanced? Preliminary Data exploration

```{r}
BehaveDat = read.csv("BehavioralData_New.csv", header = T) #Behavioural Data only
BehaveDat = subset(BehaveDat, select = -c(X))

SacDat = read.csv("SaccadesData_New.csv",header = T) #ET data for saccades + Behavioural Data
SacDat = subset(SacDat, select = -c(X))

ScaleData = subset(SacDat, ID == 1)
ScaleData1 = subset(SacDat, ID == 3)
ScaleData2 = rbind(ScaleData, ScaleData1)
ScaledData = ScaleData2 %>%
  group_by(ID, image) %>%
  groupdata2::group(n = 4, method = 'greedy') %>%
  summarise(
    ID = ID[1],
    age = age[1],
    gender = gender[1],
    group = group[1],
    image = image[1],
    q1 = q1[1],
    q2 = q2[1],
    q3 = q3[1],
    q4 = q4[1],
    q5 = q5[1],
    q6 = q6[1],
    q7 = q7[1],
    q8 = q8[1],
    q9 = q9[1],
    q10 = q10[1],
    q11 = q11[1],
    condition = condition[1],
    Trial = Trial[1],
    event = event[1],
    sttime = (sttime[1]+sttime[2]+sttime[3]+sttime[4])/4,
    entime = (entime[1]+entime[2]+entime[3]+entime[4])/4,
    StartPositionX = StartPositionX[1],
    StartPositionY = StartPositionY[1],
    EndPositionX = EndPositionX[1],
    EndPositionY = EndPositionY[1],
    avel = avel[1],
    pvel = pvel[1],
    Duration = Duration[1],
    Number_sac = Number_sac[1],
    artist = artist[1],
    genre = genre[1]
  )

ScaledData = subset(ScaledData, select = -c(.groups))
SacDat = SacDat[!(SacDat$ID==1),]
SacDat = SacDat[!(SacDat$ID==3),]
SacDat = rbind(SacDat,ScaledData)
SacDat = SacDat[order(SacDat$ID),]

FixDat = read.csv("FixationsData_New.csv", header = T) #ET data for fixations + Behavioural Data
FixDat = subset(FixDat, select = -c(X))

ScaleDataFix = subset(FixDat, ID == 1)
ScaleDataFix1 = subset(FixDat, ID == 3)
ScaleDataFix2 = rbind(ScaleDataFix, ScaleDataFix1)
ScaledDataFix = ScaleDataFix2 %>%
  group_by(ID, image) %>%
  groupdata2::group(n = 4, method = 'greedy') %>%
  summarise(
    ID = ID[1],
    age = age[1],
    gender = gender[1],
    group = group[1],
    image = image[1],
    q1 = q1[1],
    q2 = q2[1],
    q3 = q3[1],
    q4 = q4[1],
    q5 = q5[1],
    q6 = q6[1],
    q7 = q7[1],
    q8 = q8[1],
    q9 = q9[1],
    q10 = q10[1],
    q11 = q11[1],
    condition = condition[1],
    Trial = Trial[1],
    event = event[1],
    sttime = (sttime[1]+sttime[2]+sttime[3]+sttime[4])/4,
    entime = (entime[1]+entime[2]+entime[3]+entime[4])/4,
    PositionX = PositionX[1],
    PositionY = PositionY[1],
    Duration = Duration[1],
    Number_fix = Number_fix[1],
    artist = artist[1],
    genre = genre[1]
  )

ScaledDataFix = subset(ScaledDataFix, select = -c(.groups))
FixDat = FixDat[!(FixDat$ID==1),]
FixDat = FixDat[!(FixDat$ID==3),]
FixDat = rbind(FixDat,ScaledDataFix)
FixDat = FixDat[order(FixDat$ID),]

#Looking at the population:
Experts = subset(BehaveDat, condition == 1)
NonExperts = subset(BehaveDat, condition == 0)
summary(Experts$gender)/40 #The reason female is not a whole number - ID 1 saw only 39 images
summary(NonExperts$gender)/40
mean(Experts$age)
mean(NonExperts$age)
summary(BehaveDat$q7)/27
summary(BehaveDat$q7[BehaveDat$condition == 1])/13
summary(BehaveDat$q7[BehaveDat$condition == 0])/14
#On average, each participants has seen 1.9 image out of 40 - (it's divided by the number of participants)
summary(BehaveDat$image[BehaveDat$q7 == "yes"]) #Most familiar images - so far it's schiele
length(BehaveDat$ID[BehaveDat$q11 == "yes"])/40 #How many people have taken art-classes? - again, not a whole number because of ID 1
summary(BehaveDat$image[BehaveDat$q7 == "yes"])

BehaveDat2 <- BehaveDat %>% #summarizing mean of ratings for each participants 
  group_by(ID) %>%
  summarize(
    q1 = q1[1],
    q2 = q2[1],
    q3 = q3[1],
    q4 = q4[1],
    q5 = q5[1],
    q6 = q6[1],
    q7 = q7[1],
    q8 = q8[1],
    q9 = q9[1],
    q10 = q10[1],
    q11 = q11[1],
    condition = condition[1]
  )

plot1 <- ggplot(BehaveDat2,aes(y=q1,x=condition))+geom_boxplot()+ggtitle("Go to a museum to see this picture?")+
  xlab("Condition") + ylab("Question 1")
plot2 <- ggplot(BehaveDat2,aes(y=q2,x=condition))+geom_boxplot()+ggtitle("Recommend others to do the same?")
plot3 <- ggplot(BehaveDat2,aes(y=q3,x=condition))+geom_boxplot()+ggtitle("Buy this picture?")
plot4 <- ggplot(BehaveDat2,aes(y=q4,x=condition))+geom_boxplot()+ggtitle("Explain the main idea?")
plot5 <- ggplot(BehaveDat2,aes(y=q5,x=condition))+geom_boxplot()+ggtitle("Identify other artworks by same artist? ")
plot6 <- ggplot(BehaveDat2,aes(y=q6,x=condition))+geom_boxplot()+ggtitle("Explain the main idea behind similar artworks?")

ggarrange(
  plot1,
  plot2,
  plot3, 
  plot4,
  plot5,
  plot6
)

#plot7 <- ggplot(BehaveDat2,aes(x=q7))+geom_bar(fill = "#999999")+facet_wrap(~condition)+
 # xlab("Question 7") + ylab("Number of Participants")
plot8 <- ggplot(BehaveDat2,aes(y=q8,x=condition))+geom_boxplot()+xlab("Condition")+ylab("Rating")+ggtitle("Question 8")+coord_cartesian(ylim = c(1, 7))
plot9 <- ggplot(BehaveDat2,aes(y=q9,x=condition))+geom_boxplot()+xlab("Condition")+ylab("Rating")+ggtitle("Question 9")+ coord_cartesian(ylim = c(1, 7))
plot10 <- ggplot(BehaveDat2,aes(y=q10,x=condition))+geom_boxplot()+xlab("Condition")+ylab("Rating") + ggtitle("Question 10") + coord_cartesian(ylim = c(1,7))
plot11 <- ggplot(BehaveDat2,aes(x = q11))+geom_bar(fill = "#999999")+facet_wrap(~condition)+ xlab("Question 11") + ylab("Number of Participants")+ggtitle("Question 11")

BehaveDat2$q11 = plyr::revalue(BehaveDat2$q11,c("yes"="1","no"="0"))

ggarrange(
  plot8,
  plot9,
  plot10,
  plot11
)

ggarrange(
  plot7,
  plot11

)

#Group 1 appears to be more intersted in art - could be influenced by the briefing 
#Let's test if the difference is signifcant
#$q8 = as.factor(BehaveDat2$q8)
#BehaveDat2$q9 = as.factor(BehaveDat2$q9)
#BehaveDat2$q10 = as.factor(BehaveDat2$q10)

mean(BehaveDat2$q8[BehaveDat2$condition == 1])
sd(BehaveDat$q8[BehaveDat2$condition == 1])
mean(BehaveDat2$q8[BehaveDat2$condition == 0])
sd(BehaveDat$q8[BehaveDat2$condition == 0])

mean(BehaveDat2$q9[BehaveDat2$condition == 1])
sd(BehaveDat$q9[BehaveDat2$condition == 1])
mean(BehaveDat2$q9[BehaveDat2$condition == 0])
sd(BehaveDat$q9[BehaveDat2$condition == 0])

mean(BehaveDat2$q10[BehaveDat2$condition == 1])
sd(BehaveDat$q10[BehaveDat2$condition == 1])
mean(BehaveDat2$q10[BehaveDat2$condition == 0])
sd(BehaveDat$q10[BehaveDat2$condition == 0])


InterestModel = glm(condition ~ 1 + q8 + q9 + q10, family = binomial, BehaveDat2)
summary(InterestModel)

mq7 = glm(q7 ~ condition, family = binomial, BehaveDat2)
mq8 = glm(q8 ~ condition, family = poisson,BehaveDat2)
mq9 = glm(q9 ~ condition,family = binomial(link = "logit"),BehaveDat2)
mq10 = glm(q10 ~ condition,family = binomial(link = "logit"),BehaveDat2)
mq11 = glm(q11 ~ condition,family = binomial, BehaveDat2)

BehaveDat2$q11 = plyr::revalue(BehaveDat2$q11,c("1"="yes","0"="no"))
```

Assessing quality of ET-data
```{r}
#Heatmaps and scanpaths
#Subsetting dataframe to make heatmaps for 4 chosen images - all participants included
heat1 = subset(FixDat, image == "images_schiele\\fig_11.png")
heat2 = subset(FixDat, image == "images_rothko\\abstract_6.png")
heat3 = subset(FixDat, image == "images_pollock\\abstract_17.png")
heat4 = subset(FixDat, image == "images_chagall\\fig_8.png")

jet.colors = colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))

img <- png::readPNG("images for heatmaps and scanpaths/screenshot_fig11.png")
g <- grid::rasterGrob(img, interpolate = T)
ggplot(subset(ScaledDataFix, ID == 1 & image == "images_schiele\\fig_11.png"),aes(x = PositionX, y = 1081-PositionY)) +
  xlim(0,1920) +
  ylim(0,1080) +
  annotation_custom(g,xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) + scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans='sqrt')

img <- png::readPNG("images for heatmaps and scanpaths/screenshot_abs17.png")
g <- grid::rasterGrob(img,interpolate = T)
ggplot(subset(heat3, ID == 1), aes(x = PositionX, y = 1081-PositionY)) +
  xlim(0,1920) +
  ylim(0,1080) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) +
scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans='sqrt')

img <- png::readPNG("abstract_6.png")
g <- grid::rasterGrob(img,interpolate = T)
ggplot(subset(heat2, ID == 8), aes(x = PositionX, y = 1081-PositionY)) +
  xlim(0,1920) +
  ylim(0,1080) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) +
scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans='sqrt')

img <- png::readPNG("fig_8.png")
g <- grid::rasterGrob(img,interpolate = T)
ggplot(heat4, aes(x = PositionX, y = 1081-PositionY)) +
  xlim(0,1920) +
  ylim(0,1080) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) +
scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans='sqrt')

#Scanpath -
img <- png::readPNG("fig_11.png")
g <- grid::rasterGrob(img,interpolate = T)
ggplot(subset(heat1, ID == 1), aes(x = PositionX, y = 1081-PositionY)) +
  xlim(0,1920) +
  ylim(0, 1080) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) +
  geom_point(size = 5, alpha = 0.5, color = "white") + 
  geom_path(size = 1, alpha = 0.3)

img <- png::readPNG("abstract_17.png")
g <- grid::rasterGrob(img,interpolate = T)
ggplot(heat3, aes(x = PositionX, y = 1081-PositionY)) +
  xlim(0,1920) +
  ylim(0, 1080) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) +
  geom_point(size = 5, alpha = 0.5, color = "white") + 
  geom_path(size = 1, alpha = 0.3) 

img <- png::readPNG("abstract_6.png")
g <- grid::rasterGrob(img,interpolate = T)
ggplot(heat2, aes(x = PositionX, y = 1081-PositionY)) +
  xlim(0,1920) +
  ylim(0, 1080) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) +
  geom_point(size = 5, alpha = 0.5, color = "white") + 
  geom_path(size = 1, alpha = 0.3) 

img <- png::readPNG("fig_8.png")
g <- grid::rasterGrob(img,interpolate = T)
ggplot(heat4, aes(x = PositionX, y = 1081-PositionY)) +
  xlim(0,1920) +
  ylim(0, 1080) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) +
  geom_point(size = 5, alpha = 0.5, color = "white") + 
  geom_path(size = 1, alpha = 0.3) 

FixDat$Duration = as.numeric(FixDat$Duration)

#Density plot for saccades and fixation duration - Poisson
ggplot(subset(SacDat,SacDat$Duration < 300), aes(Duration, na.rm = T)) + geom_density() + ggtitle("Density - Duration of Saccades")

#Removing saccades with a duration over 300 - that's mistakes
SacDat = subset(SacDat,SacDat$Duration < 300)

ggplot(FixDat, aes(Duration,na.rm = T)) + geom_density() + ggtitle("Density - Duration of Fixations")

#Values to exclude based on their duration - saccades only 300 ms 
#Frequency of saccades
SacDat2  <- SacDat %>% 
  group_by(ID) %>%
  summarize(Number_sac = Number_sac[1])

FixDat2  <- FixDat %>% 
  group_by(ID) %>%
  summarize(Number_fix = Number_fix[1])

ggplot(FixDat2, aes(Number_fix,na.rm = T)) + geom_density()

```

#Rating models - can condition explain ratings?

```{r}
BehaveDat3 <- BehaveDat %>% #summarizing mean of ratings for each participants 
  group_by(image, condition) %>%
  summarize(
    q1 = q1[1],
    q2 = q2[1],
    q3 = q3[1],
    q4 = q4[1],
    q5 = q5[1],
    q6 = q6[1],
    q7 = q7[1],
    q8 = q8[1],
    q9 = q9[1],
    q10 = q10[1],
    q11 = q11[1]
  )

#Does it make sense to make means??? Check distributions - huge spread?  Does it matter?
ggplot(BehaveDat2, aes(q8, na.rm = T)) + geom_density()


##Models will be run first with the mean, then if time with the 
#Median is more meaningful



m1.1 = lmerTest::lmer(LikingMean ~ 1 + condition + (1|ID),BehaveDat3)
m1.2 = lmerTest::lmer(UnderstandingMean ~ 1 + condtion + (1|ID),BehaveDat3)


#Adding category, gender, the art interest - looking at the predictors

#Remember! ET data is NOT normally distributed! Family = possion OR family = gaussian(log = "link")
```

### Eyetracking models

```{r}
#Making 1) df with the Number of Fix + Number og Sacs and 2) a df with the Duration of Fix and Duration of Sacs

test1 <- FixDat %>% 
  group_by(ID, image) %>%
  summarize(
    condition = condition[1],
    Trial = Trial[1],
    Number_fix = Number_fix[1],
    artist = artist[1],
    genre = genre[1]
  )

test2 <- SacDat %>% 
  group_by(ID, image) %>%
  summarize(
    condition = condition[1],
    Trial = Trial[1],
    Number_sac = Number_sac[1],
    artist = artist[1],
    genre = genre[1]
  )


m1Data <- merge(test1,test2, by = c("ID","image"))
m1Data <- subset(m1Data, select = -c(Trial.y,condition.y,artist.y,genre.y))
m1Data <- plyr::rename(m1Data,c("condition.x"="condition","Trial.x"="Trial","artist.x"="artist","genre.x"="genre"))

#Can condition be predicted based on fix and sac?
m2.1 <- glmer(condition ~ 1 + Number_fix*Number_sac + (1 + Number_fix + Number_sac|ID) + (1 + Number_fix + Number_sac|image), family = "binomial", data = m1Data, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))


m2.2 <- glmer(condition ~ 1 + Duration_fix*Duration_sac + (1 + Duration_fix + Duration_sac|ID) + (1 + Duration_fix + Duration_sac|image), family = "binomial", data = data)


##Adding genre and arist into the mix
m2.3 <- glmer(condition ~ 1 + Number_fix*Number_sac*genre + (1 + Number_fix + Number_sac|ID) + (1 + Number_fix + Number_sac|image), family = "binomial", data = data)

m2.4 <- glmer(condition ~ 1 + Number_fix*Number_sac*artist + (1 + Number_fix + Number_sac|ID) + (1 + Number_fix + Number_sac|image), family = "binomial", data = data)


m2.5 <- glmer(condition ~ 1 + Duration_fix*Duration_sac*genre + (1 + Duration_fix + Duration_sac|ID) + (1 + Duration_fix + Duration_sac|image), family = "binomial", data = data)

m2.6 <- glmer(condition ~ 1 + Duration_fix*Duration_sac*artist + (1 + Duration_fix + Duration_sac|ID) + (1 + Duration_fix + Duration_sac|image), family = "binomial", data = data)


m2.7 <- glmer(condition ~ 1 + Number_fix*Number_sac*genre*artist + (1 + Number_fix + Number_sac|ID) + (1 + Number_fix + Number_sac|image), family = "binomial", data = data)

m2.8 <- glmer(condition ~ 1 + Duration_fix*Duration_sac*genre*artist + (1 + Duration_fix + Duration_sac|ID) + (1 + Duration_fix + Duration_sac|image), family = "binomial", data = data)


```


summary(m1)
  #Defing a function to get performance
getPerformance = function(test_df, train_df, mdl, mdl_string, n = NA){
  #asses performance and returns a result df
  
    #save perf to list
      #Test performance
  
  #extract predicted value from the mdl string to use in the rmse
  temp_string = gsub("(\\~).+", mdl_string, replacement = "")
  actual_col = gsub(" ", x = temp_string, replacement = "")
  actual =pull(dplyr::select(test_df, actual_col))
  #calculating rmse
  rmse = hydroGOF::rmse(predict(mdl, test_df, allow.new.levels = T), actual , na.rm = T)
  mdlPerf = summary(mdl)
    #saving performance metrix to a df
  result_df =  data.frame(rmse = rmse,
                          AIC = mdlPerf$AICtab[1],
                          BIC = mdlPerf$AICtab[2],
                          LogLik = mdlPerf$AICtab[3],
                          n = n) 
  return(result_df)
} #Getting performance
  #defining a cross validate function
CrossVal = function(num_folds, dataset, mdl_string, ID_col = NULL, CAT_col = NULL, glmer = T, link = "log") {
  
  #folding the dataset
  dataset = fold(dataset, num_folds, cat_col = CAT_col, id_col = ID_col, method = 'n_dist')
  
  #looping through the folds
  for (fold in seq(num_folds)) {
    train_df = subset(dataset, .folds != fold)
    test_df = subset(dataset, .folds == fold)
    
    if (glmer == T){
      if (link == "log"){
        #train data on all except the fold
        mdl = try(glmer(mdl_string, train_df, family = gaussian(link = "log"), 
                        control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE)))
      } else {
        #train data on all except the fold
        mdl = try(glmer(mdl_string, train_df, family = gaussian, 
                        control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE)))
      }
    } else {
      mdl = try(glm(mdl_string, train_df, family = gaussian(link = "log")))
    }
    temp_sum = try(summary(mdl))
    if (length(temp_sum) > 3){ #if you could make a model
      #asses performance and append it to a df
      temp = getPerformance(test_df, train_df, mdl, mdl_string, n = fold)
    } else {#if you couldn't make a model
      temp = data.frame(rmse = NA,
                        AIC = NA,
                        BIC = NA,
                        LogLik = NA,
                        n = n)
    }
    temp$mdl = mdl_string
    temp$numfolds = num_folds
    if (fold == 1){ #if first part - make a df
      perf_df = temp
    } else { #else append to df
      perf_df = rbind(perf_df, temp)  
    }
    
  }
  return(perf_df)
}
se_mdl_list = c("PupilSize ~ 1 + Ostensive*Direction + (1 + Ostensive*Direction|ParticipantID)", 
             "PupilSize ~ 1 + Ostensive*Direction + Trial + (1 + Ostensive*Direction + Trial|ParticipantID)",
             "PupilSize ~ 1 + Ostensive*Direction*Trial + (1 + Ostensive*Direction*Trial|ParticipantID)",
             "PupilSize ~ 1 + Ostensive + Direction + (1 + Ostensive+Direction|ParticipantID)", 
             "PupilSize ~ 1 + Ostensive + (1 + Ostensive|ParticipantID)", 
             "PupilSize ~ 1 + Direction + (1 + Direction|ParticipantID)"
             )
time.start = proc.time()
for (model_string in se_mdl_list){ #apply CrossVal to all of the model variations
  temp = CrossVal(num_folds = 3, dataset = se_df, mdl_string = model_string, ID_col = "ParticipantID", CAT_col = NULL, glmer = T)
  if (model_string == se_mdl_list[1]){
    se_perf_df = temp
  } else {
    se_perf_df = rbind(se_perf_df, temp)
  }
  print(paste("Running for (model_string in se_mdl_list)",
          round(match(model_string, se_mdl_list)/length(se_mdl_list)*100), 
          "%", "- in", round((proc.time() - time.start)[3], 2), "seconds"), sep =  "") 
}
se_perf_df_sum = group_by(se_perf_df, mdl) %>%
  summarise_all(funs(mean(., na.rm = TRUE)))

###Visual Seach models
  #visual seach patterns are affected by task structure
vs_fix <-  subset(df_fix1, Task == "VisualSearch")
vs_sac <-  subset(df_sac1, Task == "VisualSearch")
  #the to primary models 
m2 = glmer(Duration ~ SearchType*Fixation +  (1 + SearchType*Fixation|ParticipantID), vs_fix, 
           family = gaussian(link = "log"), 
           control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))
m3 = glmer(Amplitude ~ SearchType*Saccade + (1 + SearchType*Saccade|ParticipantID), vs_sac, 
           family = gaussian(link = "log"), 
           control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))
summary(m2)
summary(m3)
  
  #variations of the two models
m2_list = c("Duration ~ SearchType*Fixation + (1 + SearchType*Fixation|ParticipantID)", 
             "Duration ~ SearchType+Fixation + (1 + SearchType+Fixation|ParticipantID)", 
             "Duration ~ SearchType + (1 + SearchType|ParticipantID)" 
             )
m3_list = c("Amplitude ~ SearchType*Saccade + (1 + SearchType*Saccade|ParticipantID)", 
             "Amplitude ~ SearchType+Saccade + (1 + SearchType+Saccade|ParticipantID)", 
             "Amplitude ~ SearchType + (1 + SearchType|ParticipantID)" 
             )
  #setting vectors to be the right types
vs_fix$Task = as.factor(as.character(vs_fix$Task))
vs_fix$Trial = as.integer(vs_fix$Trial)
vs_fix$ParticipantID = droplevels(vs_fix$ParticipantID)
vs_fix$SearchType = as.factor(vs_fix$SearchType)
  #CrossVal of the two models
time.start = proc.time()
for (model_string in m2_list){ #apply CrossVal to all of the model variations
  temp = CrossVal(num_folds = 3, dataset = vs_fix, mdl_string = model_string, ID_col = "ParticipantID", CAT_col = NULL, glmer = T)
  if (model_string == m2_list[1]){
    vs_perf_df1 = temp
  } else {
    vs_perf_df1 = rbind(vs_perf_df1, temp)
  }
  print(paste("Running for (model_string in m2_list)",
          round(match(model_string, m2_list)/length(m2_list)*100), 
          "%", "- in", round((proc.time() - time.start)[3], 2), "seconds"), sep =  "") 
}
vs_perf_df1_sum = group_by(vs_perf_df1, mdl) %>%
  summarise_all(funs(mean(., na.rm = TRUE)))
time.start = proc.time()
for (model_string in m3_list){ #apply CrossVal to all of the model variations
  temp = CrossVal(num_folds = 3, dataset = vs_sac, mdl_string = model_string, ID_col = "ParticipantID", CAT_col = NULL, glmer = T)
  if (model_string == m3_list[1]){
    vs_perf_df2 = temp
  } else {
    vs_perf_df2 = rbind(vs_perf_df1, temp)
  }
  print(paste("Running for (model_string in m3_list)",
          round(match(model_string, m3_list)/length(m3_list)*100), 
          "%", "- in", round((proc.time() - time.start)[3], 2), "seconds"), sep =  "") 
}
vs_perf_df2_sum = group_by(vs_perf_df2, mdl) %>%
  summarise_all(funs(mean(., na.rm = TRUE)))
  #updated versions of the original models based on the crossVal 
m2 = glmer(Duration ~ SearchType + (1 + SearchType|ParticipantID), vs_fix, 
           family = gaussian(link = "log"), 
           control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))
m3 = glmer(Amplitude ~ SearchType + (1 + SearchType|ParticipantID), vs_sac, 
           family = gaussian(link = "log"), 
           control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))
summary(m2)
summary(m3)

#setting vectors to be the right types
fold_VS$Task = as.factor(as.character(fold_VS$Task))
fold_VS$Trial = as.integer(fold_VS$Trial)
fold_VS$ParticipantID = droplevels(fold_VS$ParticipantID)
fold_VS$SearchType = as.factor(fold_VS$SearchType)
perf_df = cross_validate(data = fold_VS, models = "Duration ~ SearchType + (1 + SearchType|ParticipantID)", folds_col = ".folds", family = "gaussian",
  link = "log")
perf_df
